\chapter{Zusammenfassung und Ausblick}
\label{sec:zusammenfassung_ausblick}
Die Arbeit war teilweise erfolgreich darin, eine Charaktersteuerung mit dem Unity ML-Agents Paket zu entwickeln und zu trainieren. Es konnten Anpassungen aufgezeigt werden, um das Modell an die spezifischen Anforderungen eines kontrollierbaren Spielcharakters anzupassen. Auch wenn diese im limitierten Zeitspektrum dieser Arbeit nicht kombiniert werden konnten, wurde klar ersichtlich, dass die Bewegungsabläufe für den Läufer erlernbar waren. Im weiteren konnte die Kompatibilität für unterschiedliche Charaktermodelle durch die Anpassungen erreicht und das optische Erscheinungsbild der Gangbewegung außerdem auch auf ein neues Level gebracht werden. Als größte Herausforderung zeigte sich jedoch das Antrainieren mehrerer Bewegungsabläufe (Skills) in einem einzigen Modell. Im Artikel \grqq{}DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills\grqq{} wird hierfür ein Skill Selector Modell trainiert, das als Input die Auswahl des aktuell geforderten Skills erhält und entscheidet, welcher Skill aktiviert werden soll. Der Skill Selector kann sogar mehrere Skills gleichzeitig aktivieren, wodurch fließende Übergänge zwischen den Bewegungen möglich sind.\cite{peng2018deepmimic} Dieses Verfahren erfordert jedoch tiefgreifende Anpassungen an den grundlegenden Konzepten der Lernalgorithmen und war daher in dieser Arbeit nicht realisierbar.

Aus erarbeiteten Ergebnissen lässt sich ableiten, dass mit dem Unity ML-Agents Paket durchaus charaktersteuernde Modelle trainiert werden können, die zusätzlich über Nutzerinput steuerbar sind. Somit erscheint der Ansatz, traditionelle Animationssysteme durch ein trainiertes Modell zu ersetzen, durchaus realistisch. Die weitere Entwicklung der thematisierten Anpassungen sowie umfassendere Tests zur Stabilität sind jedoch notwendig. Beispielsweise kann der Läufer aktuell keine äußeren Kraftimpulse kompensieren, was die Fähigkeit zur Erholung von Stürzen und das Anpassen an Unebenheiten im Untergrund zu wesentlichen Themen für zukünftige Arbeiten macht. Aus diesen Ergebnissen und Impulsen für zukünftige Implementierungen lässt sich ableiten, dass mit dem aktuellen Stand der Entwicklung höchstens sehr vereinfachte Spieletitel ein solches System in Erwägung ziehen sollten. Andere Arbeiten in diesem Bereich, wie die von Nvidia und Ubisoft entwickelten Systeme, zeigen jedoch, dass ähnliche Lösungen in anderen Entwicklungsumgebungen mit umfassenderen Ressourcen bereits erfolgreich umgesetzt wurden.\cite{2022-TOG-ASE}\cite{10.1145/3355089.3356536} Insbesondere Ubisoft nutzte denselben Lernalgorithmus für die Entwicklung ihrer Charaktersteuerung.

Zukünftig wird die Verwendung von maschinellem Lernen im Bereich der Charakteranimation sicher Realität werden. Abgesehen von kompetitiven Spielen, bei denen ein gleichbleibendes, vorhersehbares Verhalten erwünscht ist, könnte die Nutzung von physikalisch simulierten Charakterkontrollern durch maschinelles Lernen den Aufwand für das Erstellen natürlicher Bewegungsabläufe drastisch reduzieren. Zudem ermöglicht die physikalische Simulation eine Interaktion mit der Umgebung, die unter kinematischen Animationssystemen bisher nicht möglich war.